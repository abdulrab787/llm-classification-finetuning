{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba370eb3",
   "metadata": {},
   "source": [
    "# 02 - Data Preprocessing\n",
    "This notebook handles text preprocessing and data preparation for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1793d5",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c0b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc15e6bb",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280a54cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train shape: (57477, 9)\n",
      "Original test shape: (3, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "print(f\"Original train shape: {train_df.shape}\")\n",
    "print(f\"Original test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd6969",
   "metadata": {},
   "source": [
    "## Text Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f7328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning function defined.\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean text by:\n",
    "    - Converting to lowercase\n",
    "    - Removing special characters\n",
    "    - Removing extra whitespace\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(\"Text cleaning function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db350029",
   "metadata": {},
   "source": [
    "## Apply Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa85617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n",
      "Cleaning text columns...\n",
      "Cleaning prompt...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clean_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m train_df.columns:\n\u001b[32m     14\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCleaning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m         train_df[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_clean\u001b[39m\u001b[33m'\u001b[39m] = train_df[col].apply(\u001b[43mclean_text\u001b[49m)\n\u001b[32m     16\u001b[39m         test_df[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_clean\u001b[39m\u001b[33m'\u001b[39m] = test_df[col].apply(clean_text)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCleaning complete!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'clean_text' is not defined"
     ]
    }
   ],
   "source": [
    "# Ensure dependencies are available\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define clean_text function if not already defined\n",
    "if 'clean_text' not in locals():\n",
    "    def clean_text(text):\n",
    "        \"\"\"\n",
    "        Clean text by:\n",
    "        - Converting to lowercase\n",
    "        - Removing special characters\n",
    "        - Removing extra whitespace\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Remove email addresses\n",
    "        text = re.sub(r'\\S+@\\S+', '', text)\n",
    "        \n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "\n",
    "# Ensure data is loaded\n",
    "if 'train_df' not in locals():\n",
    "    train_df = pd.read_csv('../data/train.csv')\n",
    "    test_df = pd.read_csv('../data/test.csv')\n",
    "    print(\"Data loaded.\")\n",
    "\n",
    "# Apply cleaning to training data\n",
    "print(\"Cleaning text columns...\")\n",
    "text_columns = ['prompt', 'response_a', 'response_b']\n",
    "\n",
    "for col in text_columns:\n",
    "    if col in train_df.columns:\n",
    "        print(f\"Cleaning {col}...\")\n",
    "        train_df[f'{col}_clean'] = train_df[col].apply(clean_text)\n",
    "        test_df[f'{col}_clean'] = test_df[col].apply(clean_text)\n",
    "\n",
    "print(\"\\nCleaning complete!\")\n",
    "print(f\"\\nExample of cleaning (prompt):\")\n",
    "if 'prompt' in train_df.columns:\n",
    "    print(f\"Original: {train_df['prompt'].iloc[0][:100]}...\")\n",
    "    print(f\"Cleaned: {train_df['prompt_clean'].iloc[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14466fc",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd6fa89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after cleaning: (57477, 9)\n"
     ]
    }
   ],
   "source": [
    "# Check for empty strings after cleaning\n",
    "empty_masks = []\n",
    "for col in ['prompt_clean', 'response_a_clean', 'response_b_clean']:\n",
    "    if col in train_df.columns:\n",
    "        empty_masks.append(train_df[col].str.len() == 0)\n",
    "\n",
    "if empty_masks:\n",
    "    combined_empty = empty_masks[0]\n",
    "    for mask in empty_masks[1:]:\n",
    "        combined_empty = combined_empty | mask\n",
    "    \n",
    "    print(f\"Rows with empty text fields after cleaning: {combined_empty.sum()}\")\n",
    "    \n",
    "    # Remove rows with empty text\n",
    "    train_df = train_df[~combined_empty].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train shape after cleaning: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c899822",
   "metadata": {},
   "source": [
    "## Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a58956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target label created:\n",
      "  Model A wins (0): 20064\n",
      "  Model B wins (1): 19652\n",
      "  Tie (2): 17761\n"
     ]
    }
   ],
   "source": [
    "# Create target label based on winner columns\n",
    "# We'll create a target that indicates which model won\n",
    "\n",
    "if 'winner_model_a' in train_df.columns and 'winner_model_b' in train_df.columns:\n",
    "    # Create a label: 0 for model_a wins, 1 for model_b wins, 2 for tie\n",
    "    train_df['target'] = -1  # Initialize\n",
    "    \n",
    "    # Check if any column is truly binary (contains True/False or 1/0)\n",
    "    a_sum = train_df['winner_model_a'].sum()\n",
    "    b_sum = train_df['winner_model_b'].sum()\n",
    "    \n",
    "    if a_sum > 0 or b_sum > 0:\n",
    "        # Columns contain numeric values\n",
    "        train_df.loc[train_df['winner_model_a'] == 1, 'target'] = 0\n",
    "        train_df.loc[train_df['winner_model_b'] == 1, 'target'] = 1\n",
    "        if 'winner_tie' in train_df.columns:\n",
    "            train_df.loc[train_df['winner_tie'] == 1, 'target'] = 2\n",
    "    else:\n",
    "        # Columns might contain boolean values\n",
    "        train_df.loc[train_df['winner_model_a'] == True, 'target'] = 0\n",
    "        train_df.loc[train_df['winner_model_b'] == True, 'target'] = 1\n",
    "        if 'winner_tie' in train_df.columns:\n",
    "            train_df.loc[train_df['winner_tie'] == True, 'target'] = 2\n",
    "    \n",
    "    print(\"Target label created:\")\n",
    "    print(f\"  Model A wins (0): {(train_df['target'] == 0).sum()}\")\n",
    "    print(f\"  Model B wins (1): {(train_df['target'] == 1).sum()}\")\n",
    "    print(f\"  Tie (2): {(train_df['target'] == 2).sum()}\")\n",
    "else:\n",
    "    print(\"Winner columns not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965cb75",
   "metadata": {},
   "source": [
    "## Create Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d837c278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n",
      "Target label created.\n",
      "Training set size: 45981\n",
      "Validation set size: 11496\n",
      "\n",
      "Target distribution in train set:\n",
      "target\n",
      "0    16051\n",
      "1    15721\n",
      "2    14209\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target distribution in validation set:\n",
      "target\n",
      "0    4013\n",
      "1    3931\n",
      "2    3552\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure data is loaded and preprocessed\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if 'train_df' not in locals():\n",
    "    train_df = pd.read_csv('../data/train.csv')\n",
    "    test_df = pd.read_csv('../data/test.csv')\n",
    "    print(\"Data loaded.\")\n",
    "\n",
    "# Ensure target column exists\n",
    "if 'target' not in train_df.columns:\n",
    "    if 'winner_model_a' in train_df.columns and 'winner_model_b' in train_df.columns:\n",
    "        # Create a label: 0 for model_a wins, 1 for model_b wins, 2 for tie\n",
    "        train_df['target'] = -1  # Initialize\n",
    "        \n",
    "        # Check if any column is truly binary (contains True/False or 1/0)\n",
    "        a_sum = train_df['winner_model_a'].sum()\n",
    "        b_sum = train_df['winner_model_b'].sum()\n",
    "        \n",
    "        if a_sum > 0 or b_sum > 0:\n",
    "            # Columns contain numeric values\n",
    "            train_df.loc[train_df['winner_model_a'] == 1, 'target'] = 0\n",
    "            train_df.loc[train_df['winner_model_b'] == 1, 'target'] = 1\n",
    "            if 'winner_tie' in train_df.columns:\n",
    "                train_df.loc[train_df['winner_tie'] == 1, 'target'] = 2\n",
    "        else:\n",
    "            # Columns might contain boolean values\n",
    "            train_df.loc[train_df['winner_model_a'] == True, 'target'] = 0\n",
    "            train_df.loc[train_df['winner_model_b'] == True, 'target'] = 1\n",
    "            if 'winner_tie' in train_df.columns:\n",
    "                train_df.loc[train_df['winner_tie'] == True, 'target'] = 2\n",
    "        \n",
    "        print(\"Target label created.\")\n",
    "\n",
    "# Create train/validation split\n",
    "if 'target' in train_df.columns:\n",
    "    train, val = train_test_split(\n",
    "        train_df,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=train_df['target']\n",
    "    )\n",
    "else:\n",
    "    train, val = train_test_split(\n",
    "        train_df,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "print(f\"Training set size: {len(train)}\")\n",
    "print(f\"Validation set size: {len(val)}\")\n",
    "if 'target' in train_df.columns:\n",
    "    print(f\"\\nTarget distribution in train set:\")\n",
    "    print(train['target'].value_counts().sort_index())\n",
    "    print(f\"\\nTarget distribution in validation set:\")\n",
    "    print(val['target'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e15774b",
   "metadata": {},
   "source": [
    "## Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d5b456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved!\n",
      "  - ../data/train_processed.csv\n",
      "  - ../data/val_processed.csv\n",
      "  - ../data/test_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# Save processed data\n",
    "train.to_csv('../data/train_processed.csv', index=False)\n",
    "val.to_csv('../data/val_processed.csv', index=False)\n",
    "test_df.to_csv('../data/test_processed.csv', index=False)\n",
    "\n",
    "print(\"Processed data saved!\")\n",
    "print(f\"  - ../data/train_processed.csv\")\n",
    "print(f\"  - ../data/val_processed.csv\")\n",
    "print(f\"  - ../data/test_processed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
